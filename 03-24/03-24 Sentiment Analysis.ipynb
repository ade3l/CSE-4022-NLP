{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f3e47e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.examples import sentences \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63cdb3af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple is looking at buying U.K. startup for $1 billion\n",
      "Apple PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.K. PROPN dobj\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "1 NUM compound\n",
      "billion NUM pobj\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(sentences[0])\n",
    "print(doc.text)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "861942e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d8d141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a2aabb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62815133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b5a9b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size = 0.3, random_state = 17, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c96a8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf4b9a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopwords(sentence):\n",
    "    str(sentence)\n",
    "    doc = nlp(sentence)\n",
    "    words = []\n",
    "    for token in doc:\n",
    "        if str(token) not in stopwords_list:\n",
    "            words.append(str(token))\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25f9cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(sentence):\n",
    "    str(sentence)\n",
    "    lemms = []\n",
    "    doc = nlp(sentence)\n",
    "    for token in doc:\n",
    "        lemms.append(token.lemma_)\n",
    "        \n",
    "    return ' '.join(lemms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "280a72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeSpecialChars(sentence): \n",
    "    sentence = re.sub(r'[^\\w ]+', \"\", sentence)\n",
    "    sentence = ' '.join(sentence.split())\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e7710",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_data['review']=train_data['review'].apply(lambda row: removeStopwords(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40806723",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_data['review']=train_data['review'].apply(lambda row: lemmatize(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28910cdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_data['review']=train_data['review'].apply(lambda row: removeSpecialChars(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c97a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a04c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "# stem the data\n",
    "# TFid vectorizer for feature extraction\n",
    "# tfid .fit_transform df.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777bfd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
